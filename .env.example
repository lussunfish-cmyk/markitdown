# ============================================================================
# LLM Backend Configuration
# ============================================================================

# LLM 백엔드 선택 ("ollama" 또는 "lmstudio")
LLM_BACKEND_TYPE=ollama

# ============================================================================
# Ollama Configuration (로컬 개발 환경)
# ============================================================================

# Ollama 서버 URL
# - 로컬 개발: http://localhost:11434
# - Docker에서 호스트 Ollama 접근: http://host.docker.internal:11434
OLLAMA_BASE_URL=http://localhost:11434

# 사용할 모델
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large
OLLAMA_LLM_MODEL=gemma2

# 타임아웃 및 재시도 설정
OLLAMA_TIMEOUT=300
OLLAMA_MAX_RETRIES=3
OLLAMA_RETRY_DELAY=1.0

# ============================================================================
# LM Studio Configuration (macOS 개발 환경)
# ============================================================================

# LM Studio 서버 URL
# - 로컬 개발: http://localhost:1234/api
# - Docker에서 호스트 LM Studio 접근: http://host.docker.internal:1234/api
LMSTUDIO_BASE_URL=http://localhost:1234/api

# 사용할 LLM 모델 (LM Studio에 로드된 모델 이름)
LMSTUDIO_LLM_MODEL=qwen3-32b

# 임베딩 모델 (mlx-embeddings 라이브러리 사용, macOS 전용)
# 옵션 1) 로컬 경로: ~/.lmstudio/models/mlx-community/mxbai-embed-large-v1
# 옵션 2) HuggingFace 모델명: mlx-community/mxbai-embed-large-v1 (자동 다운로드)
LMSTUDIO_EMBEDDING_MODEL=mlx-community/mxbai-embed-large-v1

# 타임아웃 및 재시도 설정
LMSTUDIO_TIMEOUT=300
LMSTUDIO_MAX_RETRIES=3
LMSTUDIO_RETRY_DELAY=1.0

# ============================================================================
# Vector Store Configuration
# ============================================================================

VECTOR_STORE_TYPE=chroma
CHROMA_COLLECTION_NAME=documents
EMBEDDING_DIM=1024

# ============================================================================
# RAG Configuration
# ============================================================================

# 검색 설정
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.5

# LLM 생성 설정
RAG_TEMPERATURE=0.3
RAG_TOP_P=0.9
RAG_MAX_TOKENS=2048
RAG_MAX_CONTEXT_LENGTH=8192

# 쿼리 최적화
RAG_ENABLE_QUERY_REWRITING=true

# ============================================================================
# Retriever Configuration
# ============================================================================

# 하이브리드 검색 가중치 (0.0=키워드만, 1.0=벡터만)
RETRIEVER_HYBRID_ALPHA=0.5

# 리랭커 설정
RETRIEVER_USE_RERANKER=true
RETRIEVER_RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# ============================================================================
# Chunking Configuration
# ============================================================================

CHUNK_SIZE=800
CHUNK_OVERLAP=200

# ============================================================================
# Logging Configuration
# ============================================================================

LOG_LEVEL=INFO
