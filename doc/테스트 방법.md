# 테스트 방법 (Python 네이티브)

이 문서는 LM Studio(LLM) + 별도 Python 임베딩 서버 환경에서 테스트를 수행하는 절차를 설명합니다.

## 1. 사전 조건

- `.venv` 생성 및 `requirements.txt` 설치 완료
- LM Studio 서버 실행 중 (`http://localhost:1234/api`)
- 임베딩 서버 실행 중 (`http://localhost:8001`)
- API 서버 실행 중 (`http://localhost:8000`)

## 2. 서버 실행

```bash
python -m uvicorn app.converter:app --host 0.0.0.0 --port 8000 --loop asyncio
```

## 3. 기본 상태 확인

```bash
curl http://localhost:8000/health
curl http://localhost:1234/api/v1/models
curl http://localhost:8001/v1/models
```

## 4. 단위/기능 테스트 실행

```bash
python test_basic.py
python test_embedding.py
python test_vector_store.py
python test_retriever.py
python test_rag.py
python test_indexer.py
```

## 5. 통합 시나리오 테스트

```bash
bash comprehensive_test.sh
```

`comprehensive_test.sh`는 아래 흐름을 검증합니다.

1. `vector_store`, `batch_state` 초기화
2. `sample.doc`를 `./input`으로 복사
3. `/convert-folder` 호출 및 자동 인덱싱
4. `/documents`로 인덱싱 상태 확인
5. `/search`, `/query`로 검색/RAG 확인

## 6. 자주 발생하는 문제

- 헬스체크 실패: LM Studio/임베딩 서버 URL 또는 포트 불일치
- 임베딩 오류: 임베딩 서버의 OpenAI 호환 API 미지원
- `.doc` 변환 실패: LibreOffice 미설치 또는 실행 권한 문제