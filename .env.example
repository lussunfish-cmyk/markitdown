# ============================================================================
# LLM Backend Configuration
# ============================================================================

# LLM 백엔드 선택 ("ollama" 또는 "lmstudio")
LLM_BACKEND_TYPE=lmstudio

# ============================================================================
# LM Studio Configuration (LLM 추론)
# ============================================================================

# LM Studio 서버 URL
LMSTUDIO_BASE_URL=http://localhost:1234/api

# 사용할 LLM 모델 (LM Studio에 로드된 모델 이름)
LMSTUDIO_LLM_MODEL=qwen3-32b

# 별도 Python 임베딩 서버(OpenAI 호환 API) URL
# 예: http://localhost:8001
LMSTUDIO_EMBEDDING_SERVICE_URL=http://localhost:8001

# 임베딩 서버에서 받을 모델명
LMSTUDIO_EMBEDDING_MODEL=mxbai-embed-large-v1

# 타임아웃 및 재시도 설정
LMSTUDIO_TIMEOUT=300
LMSTUDIO_MAX_RETRIES=3
LMSTUDIO_RETRY_DELAY=1.0

# ============================================================================
# Vector Store Configuration
# ============================================================================

VECTOR_STORE_TYPE=chroma
CHROMA_COLLECTION_NAME=documents
EMBEDDING_DIM=1024

# 저장 디렉토리
VECTOR_STORE_DIR=./vector_store
MARKITDOWN_OUTPUT_DIR=./output
MARKITDOWN_INPUT_DIR=./input
DOCUMENT_DIR=./output
INDEX_STATE_FILE=./vector_store/index_state.json
BATCH_STATE_DIR=./batch_state
TIKTOKEN_CACHE_DIR=./tiktoken_cache

# ============================================================================
# RAG Configuration
# ============================================================================

# 검색 설정
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.5

# LLM 생성 설정
RAG_TEMPERATURE=0.3
RAG_TOP_P=0.9
RAG_MAX_TOKENS=2048
RAG_MAX_CONTEXT_LENGTH=8192

# 쿼리 최적화
RAG_ENABLE_QUERY_REWRITING=true

# ============================================================================
# Retriever Configuration
# ============================================================================

# 하이브리드 검색 가중치 (0.0=키워드만, 1.0=벡터만)
RETRIEVER_HYBRID_ALPHA=0.5

# 리랭커 설정
RETRIEVER_USE_RERANKER=true
RETRIEVER_RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# ============================================================================
# Chunking Configuration
# ============================================================================

CHUNK_SIZE=800
CHUNK_OVERLAP=200

# ============================================================================
# Logging Configuration
# ============================================================================

LOG_LEVEL=INFO
